{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import uproot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the input root file through uproot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot.open('PFlowNtupleFile_QCD.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'EventTree;2308', b'EventTree;2307']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Trajectory_NStep',\n",
       " b'Trajectory_PDGID',\n",
       " b'Trajectory_PDGCharge',\n",
       " b'Trajectory_Energy',\n",
       " b'Trajectory_Px',\n",
       " b'Trajectory_Py',\n",
       " b'Trajectory_Pz',\n",
       " b'Trajectory_StepID',\n",
       " b'Trajectory_StepPDGID',\n",
       " b'Trajectory_StepEnergy',\n",
       " b'Trajectory_StepTime',\n",
       " b'Trajectory_StepInitPosX',\n",
       " b'Trajectory_StepInitPosY',\n",
       " b'Trajectory_StepInitPosZ',\n",
       " b'Trajectory_StepFinalPosX',\n",
       " b'Trajectory_StepFinalPosY',\n",
       " b'Trajectory_StepFinalPosZ',\n",
       " b'TruthParticleE',\n",
       " b'TruthParticlePx',\n",
       " b'TruthParticlePy',\n",
       " b'TruthParticlePz',\n",
       " b'TruthParticleM',\n",
       " b'TruthParticleMother1',\n",
       " b'TruthParticleMother2',\n",
       " b'new_v',\n",
       " b'Cell_E',\n",
       " b'Total_Ch_Energy',\n",
       " b'Total_Nu_Energy',\n",
       " b'True_Ch_Energy',\n",
       " b'True_Nu_Energy',\n",
       " b'cell_Energy',\n",
       " b'cellCh_Energy',\n",
       " b'cellNu_Energy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['EventTree'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer, Ch_Layer, Nu_Layer = f['EventTree'].array('cell_Energy'), f['EventTree'].array('cellCh_Energy'), f['EventTree'].array('cellNu_Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3027.1255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Nu_Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(Layer[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the images to torch tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer, Ch_Layer, Nu_Layer = torch.from_numpy(Layer), torch.from_numpy(Ch_Layer), torch.from_numpy(Nu_Layer),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 6, 100, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_block = contracting_block(Layer, 6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                            )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        print('Input Image shape : ', x.shape)\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        print('encode_block1  : ', encode_block1.shape)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        print('encode_pool1  : ', encode_pool1.shape)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        print('encode_block2  : ', encode_block2.shape)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        print('encode_pool2  : ', encode_pool2.shape)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        print('encode_block3  : ', encode_block3.shape)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        print('encode_pool3  : ', encode_pool3.shape)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        print('bottleneck1  : ', bottleneck1.shape)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        print('decode_block3  : ', decode_block3.shape)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        print('cat_layer2  : ', cat_layer2.shape)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        print('decode_block2  : ', decode_block2.shape)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        print('cat_layer1  : ', cat_layer1.shape)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        print('decode_block1  : ', decode_block1.shape)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        print('final_layer  : ', final_layer.shape)\n",
    "        return  final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(in_channel=6,out_channel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image shape :  torch.Size([10, 6, 100, 100])\n",
      "encode_block1  :  torch.Size([10, 64, 96, 96])\n",
      "encode_pool1  :  torch.Size([10, 64, 48, 48])\n",
      "encode_block2  :  torch.Size([10, 128, 44, 44])\n",
      "encode_pool2  :  torch.Size([10, 128, 22, 22])\n",
      "encode_block3  :  torch.Size([10, 256, 18, 18])\n",
      "encode_pool3  :  torch.Size([10, 256, 9, 9])\n",
      "bottleneck1  :  torch.Size([10, 256, 10, 10])\n",
      "decode_block3  :  torch.Size([10, 512, 10, 10])\n",
      "cat_layer2  :  torch.Size([10, 128, 12, 12])\n",
      "decode_block2  :  torch.Size([10, 256, 12, 12])\n",
      "cat_layer1  :  torch.Size([10, 64, 16, 16])\n",
      "decode_block1  :  torch.Size([10, 128, 16, 16])\n",
      "final_layer  :  torch.Size([10, 6, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "outputs = unet(Layer[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 12, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ConvTranspose2d??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
